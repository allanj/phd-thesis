\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Dependency-Guided Named Entity Recognition}{12}{chapter.45}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter3}{{3}{12}{Dependency-Guided Named Entity Recognition}{chapter.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Motivation}{12}{section.46}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Two sentences annotated with both dependency and named entity information. The edges on top of words represent the dependencies and the labels with IOB encoding are the entity types.\relax }}{12}{figure.caption.47}}
\newlabel{fig:dgmexample}{{3.1}{12}{Two sentences annotated with both dependency and named entity information. The edges on top of words represent the dependencies and the labels with IOB encoding are the entity types.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Related Work}{13}{section.48}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Background}{14}{section.49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Linear-chain CRFs}{14}{subsection.50}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Illustrations of possible combinations of entities for the conventional semi-CRFs model (top) and our \textsc  {dgm} model (middle), as well as the example sentence with its dependency structure (bottom).\relax }}{15}{figure.caption.53}}
\newlabel{fig:graphexample}{{3.2}{15}{Illustrations of possible combinations of entities for the conventional semi-CRFs model (top) and our \textsc {dgm} model (middle), as well as the example sentence with its dependency structure (bottom).\relax }{figure.caption.53}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Semi-Markov CRFs}{15}{subsection.57}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Our Model}{16}{section.59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}NER with Dependency Features}{16}{subsection.60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Dependency-Guided NER}{17}{subsection.61}}
\newlabel{def:1}{{3.4.2}{17}{Dependency-Guided NER}{subsection.61}{}}
\newlabel{fig:bestcase}{{3.3a}{18}{Best-case Scenario\relax }{figure.caption.64}{}}
\newlabel{sub@fig:bestcase}{{a}{18}{Best-case Scenario\relax }{figure.caption.64}{}}
\newlabel{fig:worstcase}{{3.3b}{18}{Worst-case Scenario\relax }{figure.caption.64}{}}
\newlabel{sub@fig:worstcase}{{b}{18}{Worst-case Scenario\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The best-case and worst-case scenarios of \textsc  {dgm}.\relax }}{18}{figure.caption.64}}
\newlabel{fig:scenarios_analysis}{{3.3}{18}{The best-case and worst-case scenarios of \textsc {dgm}.\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Time Complexity}{18}{subsection.63}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Number of Edges}{18}{subsection.67}}
\newlabel{sec:numedges}{{3.4.4}{18}{Number of Edges}{subsection.67}{}}
\@writefile{toc}{\contentsline {subsubsection}{Empirical Count}{19}{section*.68}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The average number of edges over all sentences in all datasets with respect to sentence length $n$. For semi-CRF, we set $L=8$. Also note that in the dataset we have $\left \delimiter 69640972 T\right \delimiter 86418188 =5$ (\textsc  {per}, \textsc  {org}, \textsc  {gpe}, \textsc  {misc}, and special label \textsc  {o} denoting non-entities)\relax }}{19}{figure.caption.69}}
\newlabel{fig:ncomplexity}{{3.4}{19}{The average number of edges over all sentences in all datasets with respect to sentence length $n$. For semi-CRF, we set $L=8$. Also note that in the dataset we have $\left \lvert T\right \rvert =5$ (\textsc {per}, \textsc {org}, \textsc {gpe}, \textsc {misc}, and special label \textsc {o} denoting non-entities)\relax }{figure.caption.69}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The average number of possible edges involved in each token when we construct the model. \relax }}{20}{table.caption.70}}
\newlabel{tab:edges}{{3.1}{20}{The average number of possible edges involved in each token when we construct the model. \relax }{table.caption.70}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experimental Setup}{20}{section.71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Features}{21}{subsection.77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Feature Representations}{21}{subsection.78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Data Statistics}{21}{subsection.81}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces The features for the example sentence in the linear-chain CRFs model.\relax }}{22}{table.caption.79}}
\newlabel{tab:linearf}{{3.2}{22}{The features for the example sentence in the linear-chain CRFs model.\relax }{table.caption.79}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces The features for the example sentence in the semi-CRFs model.\relax }}{22}{table.caption.80}}
\newlabel{tab:semif}{{3.3}{22}{The features for the example sentence in the semi-CRFs model.\relax }{table.caption.80}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Dataset statistics. \relax }}{23}{table.caption.82}}
\newlabel{tab:dgmstatistics}{{3.4}{23}{Dataset statistics. \relax }{table.caption.82}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Detailed Data Statistics and Parameter Tuning}{23}{subsection.83}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Dataset Statistics. The number of sentences and entities in the Broadcast News corpus of OntoNotes 5.0 dataset. \relax }}{23}{table.caption.84}}
\newlabel{tab:detailedstatistics}{{3.5}{23}{Dataset Statistics. The number of sentences and entities in the Broadcast News corpus of OntoNotes 5.0 dataset. \relax }{table.caption.84}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Results and Discussions}{23}{section.85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}NER Performance}{23}{subsection.86}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces NER results for all models, when given and predicted dependency trees are used and dependency features are used. Best values and the values which are not significantly different in 95\% confidence interval are put in bold.\relax }}{24}{table.caption.87}}
\newlabel{tab:ner_withdpfeatures}{{3.6}{24}{NER results for all models, when given and predicted dependency trees are used and dependency features are used. Best values and the values which are not significantly different in 95\% confidence interval are put in bold.\relax }{table.caption.87}{}}
\newlabel{fig:error_given}{{3.5a}{25}{Given dependency tree\relax }{figure.caption.90}{}}
\newlabel{sub@fig:error_given}{{a}{25}{Given dependency tree\relax }{figure.caption.90}{}}
\newlabel{fig:error_predicted}{{3.5b}{25}{Predicted dependency tree\relax }{figure.caption.90}{}}
\newlabel{sub@fig:error_predicted}{{b}{25}{Predicted dependency tree\relax }{figure.caption.90}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The effect of different dependency parses on the output of \textsc  {dgm}. These are taken out from a part of a sentence. The NER result in (a) is correct, while (b) is not.\relax }}{25}{figure.caption.90}}
\newlabel{fig:error_analysis}{{3.5}{25}{The effect of different dependency parses on the output of \textsc {dgm}. These are taken out from a part of a sentence. The NER result in (a) is correct, while (b) is not.\relax }{figure.caption.90}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces NER results for all models, when given and predicted dependency trees are used but dependency features are not used. Best values and the values which are not significantly different in 95\% confidence interval are put in bold.\relax }}{25}{table.caption.88}}
\newlabel{tab:ner_withoutdpfeatures}{{3.7}{25}{NER results for all models, when given and predicted dependency trees are used but dependency features are not used. Best values and the values which are not significantly different in 95\% confidence interval are put in bold.\relax }{table.caption.88}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}Error Analysis}{25}{subsection.91}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Speed Analysis}{26}{subsection.92}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Results on SemEval-2010 Task 1 Dataset}{26}{subsection.94}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Training time per iteration of all the models.\relax }}{27}{figure.caption.93}}
\newlabel{fig:time}{{3.6}{27}{Training time per iteration of all the models.\relax }{figure.caption.93}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Named Entity Recognition Results on the SemEval 2010 Task 1 dataset. All the models in this table use the dependency information as features.\relax }}{27}{table.caption.95}}
\newlabel{tab:semres}{{3.8}{27}{Named Entity Recognition Results on the SemEval 2010 Task 1 dataset. All the models in this table use the dependency information as features.\relax }{table.caption.95}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.9}{\ignorespaces Named Entity Recognition Results on the SemEval 2010 Task 1 dataset without dependency features. Note that \textsc  {dgm-s} and \textsc  {dgm} still utilize the dependency information to build the models.\relax }}{27}{table.caption.96}}
\newlabel{tab:semnodepres}{{3.9}{27}{Named Entity Recognition Results on the SemEval 2010 Task 1 dataset without dependency features. Note that \textsc {dgm-s} and \textsc {dgm} still utilize the dependency information to build the models.\relax }{table.caption.96}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.5}Full Results with Precision, Recall and F-score}{27}{subsection.97}}
\@writefile{lot}{\contentsline {table}{\numberline {3.10}{\ignorespaces Named Entity Recognition Results on the Broadcast News corpus of OntoNotes 5.0 dataset. All the models in this table are using the gold dependency information. Both \textsc  {dgm-s} and \textsc  {dgm} models apply the dependency information in two ways: building the model and as well as using them as features.\relax }}{28}{table.caption.98}}
\newlabel{tab:nerresult}{{3.10}{28}{Named Entity Recognition Results on the Broadcast News corpus of OntoNotes 5.0 dataset. All the models in this table are using the gold dependency information. Both \textsc {dgm-s} and \textsc {dgm} models apply the dependency information in two ways: building the model and as well as using them as features.\relax }{table.caption.98}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.11}{\ignorespaces Named Entity Recognition Results on the Broadcast News corpus of OntoNotes 5.0 dataset. All the models in this table are using the predicted dependency information from MaltParser.\relax }}{28}{table.caption.99}}
\newlabel{tab:prednerresult}{{3.11}{28}{Named Entity Recognition Results on the Broadcast News corpus of OntoNotes 5.0 dataset. All the models in this table are using the predicted dependency information from MaltParser.\relax }{table.caption.99}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.12}{\ignorespaces NER results of all models without dependency features. Note that \textsc  {dgm-s} and \textsc  {dgm} are using the gold dependency structures in their models.\relax }}{28}{table.caption.100}}
\newlabel{tab:nerresultnodep}{{3.12}{28}{NER results of all models without dependency features. Note that \textsc {dgm-s} and \textsc {dgm} are using the gold dependency structures in their models.\relax }{table.caption.100}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.13}{\ignorespaces NER Results of all models without dependency features. Note that \textsc  {dgm-s} and \textsc  {dgm} are using the predicted dependency structures in their models.\relax }}{29}{table.caption.101}}
\newlabel{tab:prednerresultnodep}{{3.13}{29}{NER Results of all models without dependency features. Note that \textsc {dgm-s} and \textsc {dgm} are using the predicted dependency structures in their models.\relax }{table.caption.101}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Conclusion}{29}{section.102}}
\@setckpt{Chapters/Chapter3}{
\setcounter{page}{30}
\setcounter{equation}{6}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{7}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{13}
\setcounter{LT@tables}{1}
\setcounter{LT@chunks}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{205}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextradate}{2}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{1}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{16}
\setcounter{bookmark@seq@number}{43}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{0}
\setcounter{ALG@line}{0}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{theorem}{1}
\setcounter{section@level}{1}
}
